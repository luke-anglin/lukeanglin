{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sympy as sympy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from scipy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy allows us to create vectors rather than lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take list 1, 2, 3 and make it a vector\n",
    "x_vector = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors have *shape*, or *direction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can create matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition/Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    A+3=\\begin{bmatrix}\n",
    "      a_{11} & a_{12} \\\\\n",
    "      a_{21} & a_{22}   \n",
    "    \\end{bmatrix}+3\n",
    "    =\\begin{bmatrix}\n",
    "      a_{11}+3 & a_{12}+3 \\\\\n",
    "      a_{21}+3 & a_{22}+3   \n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    A-3=\\begin{bmatrix}\n",
    "      a_{11} & a_{12} \\\\\n",
    "      a_{21} & a_{22}   \n",
    "    \\end{bmatrix}-3\n",
    "    =\\begin{bmatrix}\n",
    "      a_{11}-3 & a_{12}-3 \\\\\n",
    "      a_{21}-3 & a_{22}-3   \n",
    "    \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the rows/columns and add the scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly for matrices: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "A_{2 \\times 2} + B_{2 \\times 2}= \\begin{bmatrix}\n",
    "  a_{11}+b_{11} & a_{12}+b_{12} \\\\\n",
    "  a_{21}+b_{21} & a_{22}+b_{22}     \n",
    "\\end{bmatrix}_{2 \\times 2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example with `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e0c5a0f68892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmatrix2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatrix\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmatrix2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (3,2) "
     ]
    }
   ],
   "source": [
    "#Initial matrix has dimensions 2 x 3, this one should be 3 x 2\n",
    "matrix2 = np.random.rand(3,2)\n",
    "\n",
    "matrix*matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/hdmt1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplicataion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    A_{3 \\times 2} \\times C_{2 \\times 3}=&\n",
    "    \\begin{bmatrix}\n",
    "      a_{11} & a_{12} \\\\\n",
    "      a_{21} & a_{22} \\\\\n",
    "      a_{31} & a_{32}   \n",
    "    \\end{bmatrix}_{3 \\times 2}\n",
    "    \\times\n",
    "    \\begin{bmatrix}\n",
    "      c_{11} & c_{12} & c_{13} \\\\\n",
    "      c_{21} & c_{22} & c_{23} \n",
    "    \\end{bmatrix}_{2 \\times 3} \\\\\n",
    "    =&\n",
    "    \\begin{bmatrix}\n",
    "      a_{11} c_{11}+a_{12} c_{21} & a_{11} c_{12}+a_{12} c_{22} & a_{11} c_{13}+a_{12} c_{23} \\\\\n",
    "      a_{21} c_{11}+a_{22} c_{21} & a_{21} c_{12}+a_{22} c_{22} & a_{21} c_{13}+a_{22} c_{23} \\\\\n",
    "      a_{31} c_{11}+a_{32} c_{21} & a_{31} c_{12}+a_{32} c_{22} & a_{31} c_{13}+a_{32} c_{23}\n",
    "    \\end{bmatrix}_{3 \\times 3}  \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* Columns of first matrix = Rows of second matrix\\\n",
    "$$c_x=r_y$$\n",
    "\n",
    "Result:\n",
    "* A matrix of with the same amount of rows as the first matrix, and the columns of the second.\n",
    "$$r_x \\times c_y$$\n",
    "\n",
    "Memory Devices\n",
    "* C for condition, c for columns first\n",
    "* R for result, r for rows first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basis vectors** the $\\color{red}{columns}$ of the matrix, which are the $\\color{red}{\\mbox{input dimensions}}$ mapping to a certain output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Combination**:\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a701e9b8de6ac82da0fe68b425b44688d1d0b97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Span** - all possible linear combinations.  So if I have $a_{1}\\vec{v_{1}} + a_{1}\\vec{v_{2}}$, then the span is the entire 2D coordinate plane, *unless they are linearly dependent*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Dependence** - one of the vectors can be defined as a linear combination of the others.\n",
    "* Consider a third vector, $\\vec{u}$.  It would be linear dependent if: $$\\vec{u} = a\\vec{v} + b\\vec{v}$$\n",
    "* Basically, this would be having a vector that doesn't really do anything.  If I said, go 3 miles east, then four miles north, those vectors would be **linearly independent**.  But if I added on 'go five miles northeast,' that would be useless information, denoting **linear dependency**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **rank** is the dimensions of the output of a linear transformation.  It is equal to the number of columns in the column space.  When the rank is the same as the number of columns in the matrix, then it is spanning all possible dimensions, and it can be considered **full rank**\n",
    "\n",
    "A **column space** is the set of all possible outputs of a linear transformation, also known as the *span of the columns in the matrix*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Null space**, or the **kernel**, of a vector space is all vector mappings $\\vec{v}$ in  $$A\\vec{x}=\\vec{v}$$\n",
    "\n",
    "where the mapping is the 0 vector.  Everything in the column space that is *not in the kernel* is known as the image of $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially a function, taking in a vector as a parameter and outputting another vector.\n",
    "\n",
    "Two important properties:\n",
    "* Lines remain lines\n",
    "* Origin remains fixed\n",
    "\n",
    "Try to keep in mind that with any linear transformation in 2D, the *gridlines stay parallel and evenly spaced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/gwEl6Rj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, where the vector started at $(-1, 2)$, we can see that this is essentially a linear algebra distributive property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, this linear transformed $\\hat{i} and \\hat{j}$ is represented as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/4XAkDdE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can represent the linear transformation as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/cOPqkbV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common transformation is a 90&deg; counterclockwise \n",
    "* $\\hat{i}$ = \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix} \n",
    "\n",
    "* $\\hat{j}$ = \\begin{bmatrix}\n",
    "-1\\\\\n",
    "0\n",
    "\\end{bmatrix} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The big idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All matrices can be thought of as linear transformations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple transformations can be thought of as one transformation, a **composition**, the product of two transformation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/pm12ct9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that **order matters**.  The right-hand matrix (rotation) is the *first* transformation, and the left-hand (shear) is the *second* transformation.  It is similar to how in the equation $f(g(x))$, $g(x)$ is evaluated first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that said, matrix multiplication *is* associative.  That is, if we have matrices $A, B \\mbox{ and } C$\n",
    "$$A(BC) = (AB)C$$\n",
    "\n",
    "because we are just applying three transformations in the same order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **scaled area** enclosed by vector components $\\hat{i}\\mbox{ and }\\hat{j}$ is called the **determinant**\n",
    "\n",
    "* For 3D planes, the **scaled volume** is the determinant, a **parallelepiped**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinants of *linearly dependent* vectors will be zero.  Thus, solving the determinant is a way to solve for the linear dependence of two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the **orientation** of space has been **inverted** ($\\hat{i}\\mbox{ now on the right of }\\hat{j}$, the **determinant is negative**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/10AgRve.png\" title=\"source: imgur.com\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systems of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/oDtl6IR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, the matrix of the coefficients is called $A$, the variable vector is referred to as $\\vec{x}$, and the vector of the constants is known as $\\vec{v}$.  This gives us the equation:  $$A\\vec{x}=\\vec{v}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words:  Applying the transformation $A$ to vector $\\vec{x}$ makes $\\vec{x}$ land on $\\vec{v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to go from $\\vec{x}$ to $\\vec{v}$, we have to divide the matrix $A$, or **multiply by the inverse matrix,** $A^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying the transformation by the inverse transformation, $A\\times A^{-1}$, results in no change at all.  This is called the identity matrix, and has form:\n",
    "\\begin{equation*}\n",
    "\\mbox{$A\\times A^{-1}$} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the determinant is zero, than there **is no inverse matrix**, $A^{-1}$.  In 2D, this is when the output is squished on a line.  In 3D, it is squished onto a plane.  These have **ranks** of 1, and 2 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **rank** is therefore the dimensions of the output of a linear transformation. \n",
    "A **column space** is the set of all possible outputs of a linear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonsquare Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a $2 \\times 3$ matrix, $B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "B = \n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "d & e \\\\\n",
    "g & h\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would mean we have a *2D input* mapping to a *3d output*.  The number of columns map to the input, and the number of rows to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FD5UZON.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2IsfhnH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking in terms of projections help explain these.\n",
    "\n",
    "* Perpendicular:  Dot product is *zero*\n",
    "* Similar direction: Dot product is *positive*\n",
    "* Opposite direction: Dot product is *negative*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/AISfIbb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign changes, order matters.  Remember it with $\\hat{i}\\mbox{ and }\\hat{j}$.  Their dot product, with $\\hat{i}$ on the left of the cross product multiplication, would be positive.\n",
    "\n",
    "Big idea with sign? - If the first vector is on the left of the second, then the result will be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/4ncheEI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Properties:  \n",
    "* As vectors get closer to being perpendicular, the result increases\n",
    "* The result is a vector\n",
    "* Perpendicular to the parallelogram formed, considering the right hand rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the determinant, but with the first column being the basis vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/jNzBH5d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that this involves striking through the rows and then carrying out the determinant like usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any transformation from a 2D plane to the 1D number line can be equivalently thought of as a linear transformation (a $1\\times 2$ matrix) or a vector (a $2 \\times1$ cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector equivalent to this linear transformation is called the **dual vector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/9dpstM9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cramer's Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5jujVop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"logic\" behind this is that areas get scaled by the same transformation, $A$.  See [this video](https://www.youtube.com/watch?v=jBsC34PxzoM&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=12) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the basis vectors $\\hat{i}\\mbox{ and }\\hat{j}$, but we can change these and then scale them with vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating between coordinate systems uses a matrix translator of sorts, called the **change of basis matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/lxzj4iJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying the change of basis matrix written in our coordinates by the vector in the other coordinates gives the same vector in our coordinates.  If we used the inverse of the change of basis matrix instead and multiplied by our coordinates, we could translate our coordinates to the other coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A^{-1}MA$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation generally suggests a coordinate system shift.  Computing this, where $A$ is the change of basis matrix and $M$ is the transformation will result in the matrix that can translate a vector in the other coordinate system in the **same way** as it translates one in our coordinate system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors that remain on their same span when transformed.  They are only stretched or shrunk, but **not** knocked off of their span path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/wGLkAxW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn both sides into matrix-vector multiplication, we multiply $\\lambda$ by the identity matrix, $I$, which brings us to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/iSCU6wK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it turns out this can be calculated by calculating the roots of a polynomial.  Here, we can see an example of this, showing that a matrix \\begin{equation*}\n",
    "B = \n",
    "\\begin{bmatrix}\n",
    "0 & -1\\\\\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "(the rotation matrix) has no eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/llAvLzs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we can also have times where the diagonals of the matrix are the eigenvalues themselves.  This happens with diagonal matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2XBiVCK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change of basis is used in conjunction with eigenvectors and diagonal matrices to simplify computations, rerouting the coordinate system to one with eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qBNpdNM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../jupyter-styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
