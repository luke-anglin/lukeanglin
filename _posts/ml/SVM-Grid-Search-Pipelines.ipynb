{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "# Standard Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# Plot Settings\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "plt.rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Data I will use\n",
    "#Some random data from a GitHub profile\n",
    "file = 'https://aegis4048.github.io/downloads/notebooks/sample_data/unconv_MV_v5.csv'\n",
    "df = pd.read_csv(file)\n",
    "X = df['Por'].values.reshape(-1,1)\n",
    "y = df['Prod'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SVM With Various HyperRegressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Try a Support Vector Machine Regressor `sklearn.svm.SVR` with various hyper-parameters**\n",
    "- `kernel=\"linear\"` with various values for the `C` hyperparameter\n",
    "- `kernel=\"rbf\"` with various values for the `C` & `gamma` hyperparameters\n",
    "- How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vector machines, one should remember that the ```C``` parameter defines the regularization.  \n",
    "- Smaller ```C``` = misclassifications okay, we care more about general trend.  Choose one like 0.001. \n",
    "- Bigger ```C``` = missclassifications BAD. Think of predicting tumors.  We can't have false negatives! \n",
    "\n",
    "For more information on vector machines, here are some wonderful links.\n",
    "- [StatQuest Video](https://www.youtube.com/watch?v=efR1C6CvhmE&t=40s)\n",
    "- [SVM Article](https://queirozf.com/entries/choosing-c-hyperparameter-for-svm-classifiers-examples-with-scikit-learn#the-c-parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test multiple parameters, use a ```param_grid```\n",
    "\n",
    "```param_grid```'s are a list of dictionaries, with: \n",
    "* Key is a string representing the parameter keyword\n",
    "* Value is a list of the parameters you want to test\n",
    "* Multiple dictionaries if certain parameters are only used in conjunction with other parameters\n",
    "    * Confusing?  Well, take for example the ```gamma``` parameter of the ```SVR```.  It's only used if the ```rbf``` kernel is used.  Therefore, we'd need a separate dictionary because it won't work with the ```linear``` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the ```SVR``` can be found in the Sklearn docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Create the param_grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': [0.001, 1, 100, 1000]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'C': [0.001, 1, 100, 1000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our SVR, create the randomized search, fit the randomized search, and estimate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create/Construct SVR\n",
    "#We don't pass any parameters - we're gonna use a RandomizedSearchCV to find them for us.\n",
    "svm_regression = SVR()\n",
    "\n",
    "#Create the randomized search\n",
    "randomized_search = RandomizedSearchCV(estimator = svm_regression, param_distributions = param_grid, scoring = \"r2\")\n",
    "\n",
    "#Fit the randomized search\n",
    "randomized_search.fit(X = X_train, y = y_train)\n",
    "\n",
    "#Find the best estimator\n",
    "randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Custom Transformer Greatness: \n",
    "\n",
    "1. Inherit from ```TransformerMixin``` and ```BaseEstimator```\n",
    "2. Write your ```fit``` and ```transform``` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example I liked from [this](https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65) article I found on Medium, which is great for learning about custom transformers.  Simply pass features you want to remain in your dataset, and the rest will be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, let's import some data from a datset on Kaggle\n",
    "data = pd.read_csv(\"../data/kc_house_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a ```FeatureSelector``` class, which simply takes an array of Strings representing the features we want in the constructor and returns the ```DataFrame``` with just those features when it's ```transform``` method is called.  This is useful for **separating categorical and numerical** features, and running them down different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "\n",
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create unique transformers for both the categorical and numerical features.\n",
    "\n",
    "One important thing I'd like to note here.  Categorical features are **often turned into binary**.  This makes it much easier to recognize trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     2,
     51
    ]
   },
   "outputs": [],
   "source": [
    "# Custom transformer that breaks dates column into year, month and day into separate columns and\n",
    "# converts certain features to binary\n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Class constructor method that takes in a list of values as its argument\n",
    "    def __init__(self, use_dates=['year', 'month', 'day']):\n",
    "        self._use_dates = use_dates\n",
    "\n",
    "    # Return self nothing else to do here\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # Helper function to extract year from column 'dates'\n",
    "    def get_year(self, obj):\n",
    "        return str(obj)[:4]\n",
    "\n",
    "    # Helper function to extract month from column 'dates'\n",
    "    def get_month(self, obj):\n",
    "        return str(obj)[4:6]\n",
    "\n",
    "    # Helper function to extract day from column 'dates'\n",
    "    def get_day(self, obj):\n",
    "        return str(obj)[6:8]\n",
    "\n",
    "    # Helper function that converts values to Binary depending on input\n",
    "    def create_binary(self, obj):\n",
    "        if obj == 0:\n",
    "            return 'No'\n",
    "        else:\n",
    "            return 'Yes'\n",
    "\n",
    "    # Transformer method we wrote for this transformer\n",
    "    def transform(self, X, y=None):\n",
    "        # Depending on constructor argument break dates column into specified units\n",
    "        # using the helper functions written above\n",
    "        for spec in self._use_dates:\n",
    "\n",
    "            exec(\"X.loc[:,'{}'] = X['date'].apply(self.get_{})\".format(\n",
    "                spec, spec))\n",
    "        # Drop unusable column\n",
    "        X = X.drop('date', axis=1)\n",
    "\n",
    "        # Convert these columns to binary for one-hot-encoding later\n",
    "        X.loc[:, 'waterfront'] = X['waterfront'].apply(self.create_binary)\n",
    "\n",
    "        X.loc[:, 'view'] = X['view'].apply(self.create_binary)\n",
    "\n",
    "        X.loc[:, 'yr_renovated'] = X['yr_renovated'].apply(self.create_binary)\n",
    "        # returns numpy array\n",
    "        return X.values\n",
    "#Custom transformer we wrote to engineer features ( bathrooms per bedroom and/or how old the house is in 2019  ) \n",
    "#passed as boolen arguements to its constructor\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor\n",
    "    def __init__( self, bath_per_bed = True, years_old = True ):\n",
    "        self._bath_per_bed = bath_per_bed\n",
    "        self._years_old = years_old\n",
    "        \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None):\n",
    "        #Check if needed \n",
    "        if self._bath_per_bed:\n",
    "            #create new column\n",
    "            X.loc[:,'bath_per_bed'] = X['bathrooms'] / X['bedrooms']\n",
    "            #drop redundant column\n",
    "            X.drop('bathrooms', axis = 1 )\n",
    "        #Check if needed     \n",
    "        if self._years_old:\n",
    "            #create new column\n",
    "            X.loc[:,'years_old'] =  2019 - X['yr_built']\n",
    "            #drop redundant column \n",
    "            X.drop('yr_built', axis = 1)\n",
    "            \n",
    "        #Converting any infinity values in the dataset to Nan\n",
    "        X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        #returns a numpy array\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is using a ```FeatureUnion``` to push our categorical and numerical features down the desired pipelines.  Remember it like this:  You have a drain.  You pour lava and water down the same drain at different times.  You need the pipe to separate these properly.  So, you need some sort of union which allows only the higher density fluid to go down.  This sort of joint in the pipe is your ```FeatureUnion```\n",
    "\n",
    "The best part about the ```FeatureUnion``` is that in the end, everything comes back together in a nice, prettied ```DataFrame```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     14
    ]
   },
   "outputs": [],
   "source": [
    "#Categrical features to pass down the categorical pipeline \n",
    "categorical_features = ['date', 'waterfront', 'view', 'yr_renovated']\n",
    "\n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'condition', 'grade', 'sqft_basement', 'yr_built']\n",
    "\n",
    "#Defining the steps in the categorical pipeline \n",
    "categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ),\n",
    "                                  \n",
    "                                  ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                  \n",
    "                                  ( 'one_hot_encoder', OneHotEncoder( sparse = False ) ) ] )\n",
    "    \n",
    "#Defining the steps in the numerical pipeline     \n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(numerical_features) ),\n",
    "                                  \n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                  \n",
    "                                  ('imputer', SimpleImputer(strategy = 'median') ),\n",
    "                                  \n",
    "                                  ( 'std_scaler', StandardScaler() ) ] )\n",
    "\n",
    "#Combining numerical and categorical piepline into one full big pipeline horizontally \n",
    "#using FeatureUnion\n",
    "full_pipeline = FeatureUnion( transformer_list = \n",
    "                             [ \n",
    "( 'categorical_pipeline', categorical_pipeline ), \n",
    "( 'numerical_pipeline', numerical_pipeline ) \n",
    "\n",
    "                             ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that a `FeatureUnion` can **only take in transformers.** That's why no estimators were included in the above `Pipeline`.  To remedy this issue, create **another pipeline** with the estimator(s) as the final step, and the `FeatureUnion` part of the situation as the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/lukeanglin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Leave it as a dataframe becuase our pipeline is called on a \n",
    "#pandas dataframe to extract the appropriate columns, remember?\n",
    "X = data.drop('price', axis = 1)\n",
    "#You can covert the target variable to numpy \n",
    "y = data['price'].values \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n",
    "\n",
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ ( 'full_pipeline', full_pipeline),\n",
    "                                  \n",
    "                                  ( 'model', LinearRegression() ) ] )\n",
    "\n",
    "#Can call fit on it just like any other pipeline\n",
    "full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "#Can predict with it like any other pipeline\n",
    "y_pred = full_pipeline_m.predict( X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/496/1*b0rUb-3fH6bpvwVpHrcFUQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
